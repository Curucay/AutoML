
from __future__ import annotations
from dataclasses import dataclass
from typing import Tuple, List
import io
import streamlit as st
import pandas as pd
import polars as pl
import numpy as np
from pandas.api.types import (
    is_numeric_dtype,
    is_datetime64_any_dtype,
    is_datetime64tz_dtype,
)

@dataclass
class DataProfile:
    n_rows: int
    n_cols: int
    mem_usage_mb: float
    missing_total: int
    missing_ratio: float
    numeric_cols: List[str]
    categorical_cols: List[str]
    datetime_cols: List[str]
    sample: pd.DataFrame

class DataUtils:
    @staticmethod
    def read_any(file_name: str, file_bytes: bytes, **kwargs) -> pl.DataFrame:
        name = (file_name or "").lower()
        buffer = io.BytesIO(file_bytes)

        if name.endswith(".csv"):
            return pl.read_csv(buffer, **kwargs)
        if name.endswith(".parquet"):
            return pl.read_parquet(buffer, **kwargs)
        if name.endswith(".xlsx") or name.endswith(".xls"):
            import openpyxl
            import pandas as pd
            df = pd.read_excel(buffer, **kwargs)
            return pl.from_pandas(df)
        raise ValueError(f"Desteklenmeyen uzantƒ±: {name}")

    @staticmethod
    def sanitize_df(df: pl.DataFrame) -> pl.DataFrame:
        """
        "Unnamed" ile ba≈ülayan kolonlarƒ± temizler ve t√ºm kolon adlarƒ±ndaki
        gereksiz bo≈üluklarƒ± kaldƒ±rƒ±r.
        """
        # Kolon isimlerini d√ºzenle
        clean_cols = [str(c).strip() for c in df.columns]

        # Yeni kolon isimlerini uygula
        df = df.rename({old: new for old, new in zip(df.columns, clean_cols)})

        # "Unnamed" ile ba≈ülayanlarƒ± filtrele
        unnamed_cols = [c for c in df.columns if str(c).startswith("Unnamed")]
        if unnamed_cols:
            df = df.drop(unnamed_cols)

        return df

    @staticmethod
    def infer_dtypes(
            df: pl.DataFrame,
            datetime_guess: bool = True,
            coerce_threshold: float = 0.8,
            normalize_tz_to_naive_utc: bool = False,
            protected_cols: list[str] | None = None,
            protect_id_like_names: bool = True,
    ) -> pl.DataFrame:
        """
        Kolon veri tiplerini otomatik olarak tahmin eder ve d√∂n√º≈üt√ºr√ºr.
        - Tarih benzeri string kolonlarƒ± datetime tipine √ßevirir.
        - Sayƒ±sal deƒüerlere benzer kolonlarƒ± float tipine √ßevirir.
        - 'id', 'code' gibi kolonlar koruma altƒ±ndadƒ±r.
        """
        out = df.clone()

        if not datetime_guess:
            return out

        id_like = {"id", "key", "user_id", "customer_id", "kod", "code"}
        protected = set((protected_cols or []))

        # id benzeri kolonlarƒ± koru
        if protect_id_like_names:
            for c in out.columns:
                if str(c).strip().lower() in id_like:
                    protected.add(c)

        for col in out.columns:
            if col in protected:
                continue

            s = out[col]

            # sadece Utf8 tipli kolonlarƒ± d√∂n√º≈üt√ºrmeyi dene
            if s.dtype == pl.Utf8:
                # --- Tarih tipine d√∂n√º≈üt√ºrme ---
                dt_parsed = None
                common_formats = [
                    "%Y-%m-%d", "%d-%m-%Y", "%Y/%m/%d", "%d/%m/%Y",
                    "%Y.%m.%d", "%d.%m.%Y", "%Y%m%d",
                    "%d-%b-%Y", "%d %b %Y", "%b %d %Y",
                    "%Y-%m-%dT%H:%M:%S"
                ]

                for fmt in common_formats:
                    try:
                        dt_parsed = s.str.strptime(pl.Datetime, format=fmt, strict=False)
                        # ba≈üarƒ± oranƒ±nƒ± √∂l√ß (%50 √ºzeri olursa kabul et)
                        if dt_parsed.drop_nulls().len() / max(1, s.len()) > 0.5:
                            break
                    except Exception:
                        continue

                if dt_parsed is not None and dt_parsed.drop_nulls().len() / max(1, s.len()) >= coerce_threshold:
                    if normalize_tz_to_naive_utc:
                        try:
                            dt_parsed = dt_parsed.dt.replace_time_zone(None)
                        except Exception:
                            pass
                    out = out.with_columns(dt_parsed.alias(col))
                    continue

                # --- Sayƒ±sal tahmin ---
                num_parsed = s.cast(pl.Float64, strict=False)
                num_valid_ratio = num_parsed.drop_nulls().len() / max(1, s.len())
                if num_valid_ratio >= coerce_threshold:
                    out = out.with_columns(num_parsed.alias(col))
                    continue

        return out

    @staticmethod
    def validate(df: pl.DataFrame, max_rows: int = 7_000_000, max_cols: int = 5_000) -> tuple[bool, str]:
        """
        DataFrame boyutlarƒ±nƒ± kontrol eder.
        Limitleri a≈üan durumlarda False ve hata mesajƒ± d√∂nd√ºr√ºr.
        """
        n_rows, n_cols = df.height, len(df.columns)

        if n_rows > max_rows:
            return False, f"Satƒ±r sayƒ±sƒ± √ßok b√ºy√ºk: {n_rows:,} > {max_rows:,}"
        if n_cols > max_cols:
            return False, f"S√ºtun sayƒ±sƒ± √ßok b√ºy√ºk: {n_cols:,} > {max_cols:,}"

        return True, "OK"

    @staticmethod
    def _cast_series_pair(sL: pl.Series, sR: pl.Series, mode: str) -> tuple[pl.Series, pl.Series]:
        """
        ƒ∞ki serinin tipini belirtilen moda g√∂re hizalar.
        - 'string': her iki seriyi de string'e √ßevirir.
        - 'numeric': sayƒ±sal tipe √ßevirir.
        - 'datetime': tarih formatƒ±na √ßevirir.
        - 'auto': √∂nce datetime, sonra numeric, olmazsa string.
        """
        m = (mode or "auto").lower()

        if m == "string":
            return sL.cast(pl.Utf8, strict=False), sR.cast(pl.Utf8, strict=False)

        if m == "numeric":
            return sL.cast(pl.Float64, strict=False), sR.cast(pl.Float64, strict=False)

        if m == "datetime":
            return (
                sL.str.strptime(pl.Datetime, strict=False, utc=True),
                sR.str.strptime(pl.Datetime, strict=False, utc=True),
            )

        # AUTO: √∂nce datetime, sonra numeric, deƒüilse string
        try:
            dL = sL.str.strptime(pl.Datetime, strict=False, utc=True)
            dR = sR.str.strptime(pl.Datetime, strict=False, utc=True)
            if dL.drop_nulls().height / max(1, sL.height) > 0.8 and dR.drop_nulls().height / max(1, sR.height) > 0.8:
                return dL, dR
        except Exception:
            pass

        try:
            nL = sL.cast(pl.Float64, strict=False)
            nR = sR.cast(pl.Float64, strict=False)
            if nL.drop_nulls().height / max(1, sL.height) > 0.8 and nR.drop_nulls().height / max(1, sR.height) > 0.8:
                return nL, nR
        except Exception:
            pass

        return sL.cast(pl.Utf8, strict=False), sR.cast(pl.Utf8, strict=False)

    @staticmethod
    def align_dtypes_for_merge_lr(
            df_left: pl.DataFrame,
            df_right: pl.DataFrame,
            left_on: list[str],
            right_on: list[str],
            key_cast_seq: list[str] | None = None,
    ) -> tuple[pl.DataFrame, pl.DataFrame]:
        """
        ƒ∞ki DataFrame'deki anahtar kolonlarƒ±n tiplerini hizalar.
        Her e≈üle≈üme i√ßin belirli bir cast stratejisi (auto/string/numeric/datetime) kullanƒ±labilir.
        """
        if len(left_on) != len(right_on):
            raise ValueError("left_on ve right_on uzunluklarƒ± e≈üit olmalƒ±.")

        L, R = df_left.clone(), df_right.clone()

        if key_cast_seq is None:
            key_cast_seq = ["auto"] * len(left_on)
        if len(key_cast_seq) != len(left_on):
            raise ValueError("key_cast_seq uzunluƒüu anahtar sayƒ±sƒ±yla e≈üit olmalƒ±.")

        for lc, rc, mode in zip(left_on, right_on, key_cast_seq):
            if lc not in L.columns or rc not in R.columns:
                # Eksik kolon varsa string olarak varsay
                if lc in L.columns:
                    L = L.with_columns(L[lc].cast(pl.Utf8, strict=False))
                if rc in R.columns:
                    R = R.with_columns(R[rc].cast(pl.Utf8, strict=False))
                continue

            sL, sR = L[lc], R[rc]
            cL, cR = DataUtils._cast_series_pair(sL, sR, mode)
            L = L.with_columns(cL.alias(lc))
            R = R.with_columns(cR.alias(rc))

        return L, R

    @staticmethod
    def merge_safe_lr(
            df_left: pl.DataFrame,
            df_right: pl.DataFrame,
            left_on: list[str],
            right_on: list[str],
            how: str = "inner",
            suffixes: tuple[str, str] = ("_x", "_y"),
            key_cast_seq: list[str] | None = None,
    ) -> pl.DataFrame:
        """
        Farklƒ± isimli anahtar kolonlarƒ± e≈üle≈ütirerek g√ºvenli bir merge i≈ülemi ger√ßekle≈ütirir.
        - left_on / right_on: e≈üle≈üen kolon listeleri
        - key_cast_seq: her e≈üle≈üme i√ßin tip stratejisi ('auto'|'string'|'numeric'|'datetime')
        """
        if not left_on or not right_on:
            raise ValueError("left_on / right_on bo≈ü olamaz.")
        if len(left_on) != len(right_on):
            raise ValueError("left_on ve right_on uzunluklarƒ± e≈üit olmalƒ±.")

        # √ñnce tipleri hizala
        L, R = DataUtils.align_dtypes_for_merge_lr(df_left, df_right, left_on, right_on, key_cast_seq)

        # Polars join metodu
        # right_on kullanƒ±mƒ± Polars‚Äôta doƒürudan left_on ile birlikte belirtilir
        joined = L.join(
            R,
            left_on=left_on,
            right_on=right_on,
            how=how,
            suffix=suffixes[1] if suffixes else "_right"
        )

        return joined

    @staticmethod
    def convert_column_type(df: pl.DataFrame, column: str, target_type: str) -> pl.DataFrame:
        """
        Se√ßili kolonu verilen hedef t√ºre d√∂n√º≈üt√ºr√ºr.
        D√∂n√º≈ü√ºm, tipler arasƒ± doƒürudan (√∂rn: Datetime->Date) veya
        otomatik format tanƒ±ma (√∂rn: String->Date) yoluyla yapƒ±lƒ±r.
        """
        try:
            current_dtype = df[column].dtype

            # 1Ô∏è‚É£ String d√∂n√º≈ü√ºm√º
            if target_type == "string":
                df = df.with_columns(pl.col(column).cast(pl.Utf8))

            # 2Ô∏è‚É£ Sayƒ±sal d√∂n√º≈ü√ºmler
            elif target_type == "int":
                df = df.with_columns(pl.col(column).cast(pl.Int64, strict=False))
            elif target_type == "float":
                df = df.with_columns(pl.col(column).cast(pl.Float64, strict=False))

            # 3Ô∏è‚É£ Boolean d√∂n√º≈ü√ºm√º
            elif target_type == "boolean":
                df = df.with_columns(pl.col(column).cast(pl.Boolean, strict=False))

            # 4Ô∏è‚É£ Date d√∂n√º≈ü√ºm√º (Sadece Yƒ±l-Ay-G√ºn)
            elif target_type == "date":
                if current_dtype == pl.Datetime:
                    # 1. Mevcut tip Datetime ise, saati sil (Verimli)
                    df = df.with_columns(pl.col(column).cast(pl.Date))  # Bu zaten doƒüruydu
                elif current_dtype == pl.Date:
                    # 2. Zaten Date ise, dokunma
                    pass
                else:
                    # 3. Diƒüer (string, int) tiplerden geliyorsa, OTOMATƒ∞K parse et
                    df = df.with_columns(
                        pl.col(column)
                        .cast(pl.Utf8)
                        .str.strptime(pl.Datetime, format=None, strict=False)
                        .dt.date()
                    )

            # 5Ô∏è‚É£ Datetime d√∂n√º≈ü√ºm√º (Tarih + Saat)
            elif target_type == "datetime":
                if current_dtype == pl.Date:
                    # 1. Mevcut tip Date ise, saat ekle (Verimli)

                    # [HATA D√úZELTMESƒ∞ 2]
                    # .dt.datetime() metodu Date tipi √ºzerinde √ßalƒ±≈ümaz.
                    # Doƒüru y√∂ntem .cast(pl.Datetime) kullanmaktƒ±r.
                    df = df.with_columns(pl.col(column).cast(pl.Datetime))

                elif current_dtype == pl.Datetime:
                    # 2. Zaten Datetime ise, dokunma
                    pass
                else:
                    # 3. Diƒüer (string, int) tiplerden geliyorsa, OTOMATƒ∞K parse et
                    df = df.with_columns(
                        pl.col(column)
                        .cast(pl.Utf8)
                        .str.strptime(pl.Datetime, format=None, strict=False)
                    )

            return df

        except Exception as e:
            raise ValueError(f"D√∂n√º≈ü√ºm hatasƒ± ({column} -> {target_type}): {e}")

    @staticmethod
    def extract_date_parts(df: pl.DataFrame, column: str) -> pl.DataFrame:
        """
        [BONUS D√úZELTME] Docstring g√ºncellendi.
        Tarih veya Tarih/Saat s√ºtunundan yƒ±l, ay, g√ºn bilgilerini √ßƒ±karƒ±r.
        Sadece Datetime veya Date t√ºr√º s√ºtunlarda √ßalƒ±≈üƒ±r.
        """
        dtype = df[column].dtype

        # 1Ô∏è‚É£ Kontrol: S√ºtun datetime deƒüilse anlamlƒ± uyarƒ± ver
        if dtype not in (pl.Datetime, pl.Date):
            raise TypeError(
                f"'{column}' s√ºtunu {dtype} tipinde. "
                f"Yalnƒ±zca Datetime veya Date t√ºrlerinde tarih ayrƒ±≈ütƒ±rma yapƒ±labilir."
            )

        # 2Ô∏è‚É£ G√ºvenli d√∂n√º≈ü√ºm i≈ülemleri
        try:
            df = df.with_columns([
                pl.col(column).dt.year().alias(f"{column}_year"),
                pl.col(column).dt.month().alias(f"{column}_month"),
                pl.col(column).dt.day().alias(f"{column}_day"),
            ])
            return df
        except Exception as e:
            raise ValueError(f"Tarih ayrƒ±≈ütƒ±rma hatasƒ±: {e}")

    @staticmethod
    def _bytes_to_mb(nbytes: int) -> float:
        """
        Byte deƒüerini megabayt (MB) cinsine d√∂n√º≈üt√ºr√ºr.
        """
        return round(nbytes / (1024 ** 2), 3)

    @staticmethod
    def profile(df: pl.DataFrame, sample_rows: int = 1000) -> DataProfile:
        """
        Polars DataFrame i√ßin profil √ßƒ±karƒ±mƒ± yapar.
        - Satƒ±r/s√ºtun sayƒ±sƒ±
        - Bellek kullanƒ±mƒ±
        - Eksik veri oranƒ±
        - Kolon t√ºrleri (numerik, kategorik, datetime)
        - √ñrnek satƒ±rlar
        """
        n_rows, n_cols = df.height, len(df.columns)
        mem_mb = DataUtils._bytes_to_mb(df.estimated_size())

        # Eksik deƒüer sayƒ±mƒ± ‚Äî g√ºvenli versiyon
        missing_total = int(
            df.select(pl.sum_horizontal([pl.col(c).is_null().cast(pl.Int64) for c in df.columns]))[0, 0])
        missing_ratio = float(missing_total) / float(max(1, n_rows * n_cols))

        # Tip sƒ±nƒ±flandƒ±rmasƒ±
        numeric_cols = [c for c, t in zip(df.columns, df.dtypes)
                        if t in (pl.Int8, pl.Int16, pl.Int32, pl.Int64, pl.Float32, pl.Float64)]

        # pl.Date tipi de Tarih/Zaman olarak sƒ±nƒ±flandƒ±rƒ±lmalƒ±.
        datetime_cols = [c for c, t in zip(df.columns, df.dtypes) if t in (pl.Datetime, pl.Date)]

        categorical_cols = [c for c in df.columns if c not in numeric_cols + datetime_cols]

        sample = df.head(sample_rows)

        return DataProfile(
            n_rows=n_rows,
            n_cols=n_cols,
            mem_usage_mb=mem_mb,
            missing_total=int(missing_total),
            missing_ratio=round(missing_ratio, 4),
            numeric_cols=numeric_cols,
            categorical_cols=categorical_cols,
            datetime_cols=datetime_cols,
            sample=sample
        )

    # --- Tek kolon profili (Variables paneli i√ßin) -------------------------------
    @staticmethod
    def variable_profile(df: pl.DataFrame, col: str, bins: int = 40) -> dict:
        """
        Tek bir kolonun istatistiksel profilini √ßƒ±karƒ±r.
        - Sayƒ±sal kolonlar i√ßin: min, max, mean, std, histogram
        - Tarih kolonlarƒ± i√ßin: min ve max tarih
        - Kategorik kolonlar i√ßin: distinct oranƒ±
        """
        s = df[col]
        n = s.len()
        dtype = str(s.dtype)
        mem_mb = DataUtils._bytes_to_mb(s.estimated_size())

        # Eksik ve distinct metrikleri
        missing = int(s.null_count())
        missing_pct = round((missing / max(1, n)) * 100, 4)
        if s.dtype == pl.Utf8 and n > 500_000:
            distinct = int(s.approx_n_unique())
        else:
            distinct = int(s.n_unique())
        distinct_pct = round((distinct / max(1, n)) * 100, 4)

        out = {
            "dtype": dtype,
            "n": n,
            "missing": missing,
            "missing_pct": missing_pct,
            "distinct": distinct,
            "distinct_pct": distinct_pct,
            "mem_mb": round(mem_mb, 3),
            "min": None, "max": None, "mean": None, "std": None,
            "zeros": None, "zeros_pct": None,
            "neg": None, "neg_pct": None,
            "hist": None, "hist_edges": None
        }

        # --- Sayƒ±sal kolonlar ---
        if s.dtype in (pl.Int8, pl.Int16, pl.Int32, pl.Int64, pl.Float32, pl.Float64):
            s_nonnull = s.drop_nulls()
            if s_nonnull.len() > 0:
                out["min"] = float(s_nonnull.min())
                out["max"] = float(s_nonnull.max())
                out["mean"] = float(s_nonnull.mean())
                out["std"] = float(s_nonnull.std())

                zeros = int((s_nonnull == 0).sum())
                neg = int((s_nonnull < 0).sum())
                out["zeros"], out["neg"] = zeros, neg
                out["zeros_pct"] = (zeros / max(1, n)) * 100
                out["neg_pct"] = (neg / max(1, n)) * 100

                # Histogram (numpy uyumlu)
                import numpy as np
                h, edges = np.histogram(s_nonnull.to_numpy(), bins=bins)
                out["hist"], out["hist_edges"] = h.tolist(), edges.tolist()

        # --- Tarih kolonlarƒ± ---
        elif s.dtype == pl.Datetime:
            s_nonnull = s.drop_nulls()
            if s_nonnull.len() > 0:
                out["min"] = s_nonnull.min()
                out["max"] = s_nonnull.max()

        return out

    @staticmethod
    def variable_common_values(df: pl.DataFrame, col: str, top: int = 20) -> pl.DataFrame:
        """
        Kolondaki en sƒ±k g√∂r√ºlen 'top' deƒüerleri ve y√ºzdelik oranlarƒ±nƒ± d√∂nd√ºr√ºr.
        'Other values' satƒ±rƒ±nda kalan t√ºm deƒüerler √∂zetlenir.
        """
        s = df[col].cast(pl.Utf8).fill_null("NA")
        total = s.len()

        # Deƒüerlerin frekans sayƒ±mƒ±
        vc = s.value_counts(sort=True)
        top_vc = vc.head(top)

        top_count_sum = int(top_vc["count"].sum()) if top_vc.height > 0 else 0
        others_count = int(total - top_count_sum) if vc.height > top else 0

        # Frekans oranlarƒ±nƒ± hesapla
        out = top_vc.with_columns(
            (pl.col("count") / max(1, total) * 100).alias("freq_pct")
        ).rename({col: "value"})

        # ‚úÖ T√ºm kolon tiplerini Int64 + Float64 olarak sabitle
        out = out.with_columns([
            pl.col("count").cast(pl.Int64),
            pl.col("freq_pct").cast(pl.Float64)
        ])

        # 'Other values' satƒ±rƒ±nƒ± ekle
        if others_count > 0:
            other_row = pl.DataFrame({
                "value": ["Other values"],
                "count": [others_count],
                "freq_pct": [others_count / max(1, total) * 100]
            })

            # Aynƒ± ≈üemayƒ± korumak i√ßin cast et
            other_row = other_row.with_columns([
                pl.col("count").cast(pl.Int64),
                pl.col("freq_pct").cast(pl.Float64)
            ])

            out = pl.concat([out, other_row])

        return out

    # --- Tek kolon i√ßin tablo hazƒ±r istatistikler (Variables/Statistics sekmesi) ---
    @staticmethod
    def variable_quantile_table(s: pl.Series) -> pl.DataFrame:
        """
        Sayƒ±sal seriler i√ßin quantile (daƒüƒ±lƒ±m) √∂zet tablosu d√∂nd√ºr√ºr.
        - Minimum, Q1, Median, Q3, Maksimum
        - Range ve IQR hesaplarƒ± dahil
        """
        s = s.cast(pl.Float64, strict=False).drop_nulls()

        if s.is_empty():
            return pl.DataFrame({"": [], "value": []})

        q = {
            "Minimum": s.min(),
            "5-th percentile": s.quantile(0.05, interpolation="nearest"),
            "Q1": s.quantile(0.25, interpolation="nearest"),
            "median": s.median(),
            "Q3": s.quantile(0.75, interpolation="nearest"),
            "95-th percentile": s.quantile(0.95, interpolation="nearest"),
            "Maximum": s.max(),
        }

        q["Range"] = q["Maximum"] - q["Minimum"]
        q["Interquartile range (IQR)"] = q["Q3"] - q["Q1"]

        df = pl.DataFrame({
            "": list(q.keys()),
            "value": [float(v) if v is not None else None for v in q.values()]
        })

        return df

    @staticmethod
    def variable_descriptive_table(s: pl.Series) -> pl.DataFrame:
        """
        Sayƒ±sal seriler i√ßin tanƒ±mlayƒ±cƒ± istatistik tablosu olu≈üturur.
        - Ortalama, varyans, standart sapma, √ßarpƒ±klƒ±k, basƒ±klƒ±k vb.
        """
        s = s.cast(pl.Float64, strict=False).drop_nulls()

        if s.is_empty():
            return pl.DataFrame({"": [], "value": []})

        std = s.std()
        mean = s.mean()
        variance = s.var()
        sum_val = s.sum()
        mad = (s - s.median()).abs().median()

        n = s.len()
        if n > 2:
            centered = s - mean
            skew = float((centered ** 3).mean() / (std ** 3)) if std not in (0, None) else None
            kurt = float((centered ** 4).mean() / (std ** 4)) - 3 if std not in (0, None) else None
        else:
            skew, kurt = None, None

        is_inc = s.is_sorted()
        is_dec = s[::-1].is_sorted()
        monotonicity = (
            "Monotonic increasing" if is_inc else
            ("Monotonic decreasing" if is_dec else "Not monotonic")
        )

        desc = {
            "Standard deviation": std,
            "Coefficient of variation (CV)": (std / mean) if mean not in (0, None) else None,
            "Kurtosis": kurt,
            "Mean": mean,
            "Median Absolute Deviation (MAD)": mad,
            "Skewness": skew,
            "Sum": sum_val,
            "Variance": variance,
            "Monotonicity": monotonicity,
        }

        # ‚úÖ Polars strict=False veya t√ºm√ºn√º stringe √ßevir
        df = pl.DataFrame({
            "": list(desc.keys()),
            "value": [str(v) if v is not None else "‚Äî" for v in desc.values()]
        })

        return df

    @staticmethod
    def correlation_matrix(df: pl.DataFrame) -> pl.DataFrame:
        """
        Sayƒ±sal deƒüi≈ükenler i√ßin korelasyon matrisini d√∂nd√ºr√ºr (Polars vekt√∂rel).
        """
        # Sadece sayƒ±sal s√ºtunlarƒ± se√ß
        numeric_cols = [c for c, dtype in zip(df.columns, df.dtypes)
                        if dtype in (pl.Float32, pl.Float64, pl.Int32, pl.Int64)]

        if not numeric_cols:
            return pl.DataFrame({"column": [], "message": ["Sayƒ±sal deƒüi≈üken bulunamadƒ±."]})

        # Polars 0.20+ s√ºr√ºm√º i√ßin correlation_matrix
        corr = df.select(numeric_cols).to_pandas().corr(method="pearson")
        corr_df = pl.DataFrame(corr.reset_index(names="column"))
        return corr_df

    @staticmethod
    def missing_value_summary(df: pl.DataFrame) -> pl.DataFrame:
        """
        Her kolon i√ßin eksik deƒüer sayƒ±sƒ± ve oranƒ±nƒ± hesaplar (Polars vekt√∂rel).
        """
        n_rows = df.height

        summary = (
            df.select([
                pl.col(c).is_null().sum().alias(c)
                for c in df.columns
            ])
            .transpose(include_header=True, header_name="column", column_names=["missing_count"])
            .with_columns([
                (pl.col("missing_count") / n_rows * 100).alias("missing_pct")
            ])
            .sort("missing_pct", descending=True)
        )
        return summary

    # Eksik Deƒüerlerin Doldurulmasƒ±
    @staticmethod
    def get_missing_columns(df: pl.DataFrame) -> list[str]:
        """
        Eksik deƒüer (null) i√ßeren kolonlarƒ± d√∂nd√ºr√ºr.
        """
        null_counts = df.null_count().to_dicts()[0]
        return [c for c, v in null_counts.items() if v > 0]

    # === üß© 2. T√ºm Doldurma Y√∂ntemleri (Tek Nokta Tanƒ±mƒ±) ===
    @staticmethod
    def get_fill_methods() -> dict[str, str]:
        """
        Mevcut t√ºm doldurma y√∂ntemlerini (anahtar + a√ßƒ±klama) d√∂nd√ºr√ºr.
        UI ve dahili i≈ülem mantƒ±ƒüƒ± bu s√∂zl√ºkten beslenir.
        """
        return {
            "specific": "ü™Ñ Belirli bir deƒüerle doldur",
            "forward": "‚û°Ô∏è ƒ∞leri y√∂nl√º doldur (ffill)",
            "backward": "‚¨ÖÔ∏è Geri y√∂nl√º doldur (bfill)",
            "mean": "üìä Ortalama ile doldur",
            "median": "üìà Medyan ile doldur",
            "mode": "üîÅ Mod (en sƒ±k g√∂r√ºlen) ile doldur",
            "zero": "0Ô∏è‚É£ Sƒ±fƒ±r (0) ile doldur",
            "min": "üîΩ Minimum deƒüerle doldur",
            "max": "üîº Maksimum deƒüerle doldur",
            "custom": "‚úèÔ∏è Sabit (manuel) deƒüerle doldur",
        }

    # === üß© 3. Tip Bazlƒ± Uygun Y√∂ntem √ñnerisi ===
    @staticmethod
    def suggest_fill_methods(dtype: pl.DataType) -> list[str]:
        """
        Veri tipine g√∂re uygulanabilir doldurma y√∂ntemlerini d√∂nd√ºr√ºr.
        """
        if dtype in (pl.Int64, pl.Float64):
            return ["mean", "median", "mode", "min", "max", "zero", "custom"]
        elif dtype in (pl.Utf8, pl.Boolean):
            return ["mode", "custom"]
        elif dtype in (pl.Date, pl.Datetime):
            return ["forward", "backward", "mode", "custom"]
        else:
            return ["custom"]

    # === üß© 4. Doldurma Deƒüeri Hesaplama (Metoda G√∂re) ===
    @staticmethod
    def compute_fill_value(df: pl.DataFrame, column: str, method: str, custom_value=None):
        """
        Kolon ve se√ßilen metoda g√∂re doldurma deƒüerini hesaplar.
        None d√∂nerse doldurma yapƒ±lmaz (√∂rneƒüin t√ºm deƒüerler null ise).
        """
        s = df[column]

        if s.null_count() == len(s):
            # Kolon tamamen bo≈üsa hi√ßbir ≈üey yapƒ±lmaz
            return None

        if method == "mean":
            val = s.mean()
        elif method == "median":
            val = s.median()
        elif method == "mode":
            modes = s.drop_nulls().mode().to_list()
            val = modes[0] if modes else None
        elif method == "min":
            val = s.min()
        elif method == "max":
            val = s.max()
        elif method == "zero":
            val = 0
        elif method in ("specific", "custom"):
            val = custom_value
        else:
            raise ValueError(f"Desteklenmeyen doldurma y√∂ntemi: {method}")

        # Eƒüer sonu√ß hala None ise, None d√∂nd√ºr (fill_missing uyarƒ± verecek)
        return val

    @staticmethod
    def fill_missing(df: pl.DataFrame, column: str, method: str, custom_value=None) -> pl.DataFrame:
        """
        Se√ßilen kolonun eksik deƒüerlerini belirtilen metoda g√∂re doldurur.
        Polars 1.x uyumludur (fill_null(strategy) yerine forward_fill/backward_fill).
        """
        col_expr = pl.col(column)

        try:
            # 1Ô∏è‚É£ ƒ∞leri / geri doldurma
            if method == "forward":
                expr = col_expr.forward_fill()
            elif method == "backward":
                expr = col_expr.backward_fill()
            else:
                fill_val = DataUtils.compute_fill_value(df, column, method, custom_value)

                if fill_val is None:
                    # Eƒüer hesaplanabilir bir deƒüer yoksa i≈ülem yapma
                    print(f"[UYARI] '{column}' i√ßin {method} y√∂ntemiyle doldurma deƒüeri hesaplanamadƒ±. "
                          f"Kolon tamamen bo≈ü olabilir.")
                    return df  # no-op

                expr = col_expr.fill_null(fill_val)

            return df.with_columns(expr)

        except Exception as e:
            raise ValueError(f"{column} s√ºtununda doldurma hatasƒ±: {e}")




